[
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "ST 558 Final Project EDA Document",
    "section": "",
    "text": "Introduction\nThis dataset represents predictors of Diabetes. This dataset represents 253,680 survey responses to the CDC’s Behavioral Risk Factor Surveillance System (BRFSS) survey administered in 2015. The target variable (Diabetes_binary) takes on two values: 0 if no diabetes and 1 for diabetes or prediabetes.\nThe purpose of the EDA that follows is to both visually and numerically explore the relationship of variables to the target variable - the presence of diabetes. Below, I will use bar plots for categorical variables and density plots for continuous variables to visually see differences. I will also compare means and medians for continuous variables for those with and without diabetes. For categorical variables, I will calculate and compare the percentage of those that have the predictor variable in those that either have or do not have diabetes.\nThe ultimate goal of modeling is to find the best predictive model (logistic regression, classification tree, and random forest) that can be used in the prediction of the diagnosis of Diabetes. This is beneficial because Diabetes is a very prevalent chronic disease. By using a predictive model, we could potentially provide earlier diagnosis and/or monitor patients that have a higher likelihood of developing Diabetes due to certain risk factors.\nThe Diabetes_binary column takes on 3 values: 0 for no diabetes, 1 for prediabetes or diabetes.\nThe HighBP column takes on 2 values: 0 for no high blood pressure and 1 for high blood pressure.\nThe HighChol column takes on 2 values: 0 for no high cholesterol and 1 for high cholesterol.\nThe CholCheck column takes on 2 values: 0 for no cholesterol check in the last five years and 1 for cholesterol check in the last five years.\nThe BMI column is the body mass index.\nThe Smoker column takes on 2 values: 0 for having not smoked at least 100 cigarettes in lifetime and 1 for having smoked at least 100 cigarettes in lifetime.\nThe Stroke column takes on 2 values: 0 for never had a stroke and 1 for had a stroke.\nThe HeartDiseaseorAttack column takes on 2 values: 0 if no coronary heart disease or myocardial infarction and 1 if have coronary heart disease or myocardial infarction.\nThe PhysActivity column takes on 2 values: 0 if no physical activity in last 30 days outside of job and 1 if physical activity in last 30 days outside of job.\nThe Fruits column takes on 2 values: 0 if don’t consume fruit at least once per day and 1 if consumes fruit at least once per day.\nThe Veggies column takes on 2 values: 0 if don’t consume vegetables at least once per day and 1 if consumes vegetables at least once per day.\nThe HvyAlcoholConsump column takes on 2 values: 0 if man with less than 14 drinks per week or woman with less than 7 drinks per week or 1 if man with greater than or equal to 14 drinks/week and female with greater than or equal to 7 drinks per week.\nThe AnyHealthcare column takes on 2 values: 0 if no health coverage and 1 if health coverage.\nThe NoDocbcCost column takes on 2 values: 0 if didn’t refuse doctor because of cost and 1 if refused doctor because of cost.\nThe GenHlth column takes on 5 values based on rating of general health: 1 is excellent, 2 is very good, 3 good, 4 is fair, and 5 is poor.\nThe MentHlth column represents the days of poor mental health 1-30.\nThe PhysHlth column represents the days of physical illness or injury 1-30.\nThe DiffWalk column takes on 2 values: 0 if no difficulty climbing stairs or walking and 1 if difficulty climbing stairs or walking.\nThe Sex column takes on 2 values: 0 if female and 1 if male.\nThe Age column takes on 13 values: 1: 18-24 2: 25-29 3: 30-34 4: 35-39 5: 40-44 6: 45-49 7: 50-54 8: 55-59 9: 60-64 10: 65-69 11: 70-74 12: 75-79 13: 80+\nThe Education column takes on 6 values: 1: no school 2: elementary 3: some high school 4: high school graduate 5: some college 6: college graduate\nThe Income column takes on 8 values: 1: less than $10,000 2: $10,000 - $15,000 3: $15,000 - $20,000 4: $20,000 - $25,000 5: $25,000 - $35,000 6: $35,000 - $50,000 7: $50,000 - $75,000 8: more than $75,000\n\n\nData\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.3.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndiabetes_data &lt;- read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndiabetes_data$Diabetes_binary &lt;- factor(diabetes_data$Diabetes_binary, levels = c(0, 1), labels = c(\"no_diabetes\", \"diabetes\"))\n\ndiabetes_data$HighBP &lt;- factor(diabetes_data$HighBP, levels = c(0, 1), labels = c(\"no_hbp\", \"hbp\"))\n\ndiabetes_data$HighChol &lt;- factor(diabetes_data$HighChol, levels = c(0, 1), labels = c(\"no_high_chol\", \"high_chol\"))\n\ndiabetes_data$CholCheck &lt;- factor(diabetes_data$CholCheck, levels = c(0, 1), labels = c(\"no_chol_check\", \"chol_check\"))\n\ndiabetes_data$Smoker &lt;- factor(diabetes_data$Smoker, levels = c(0, 1), labels = c(\"non_smoker\", \"smoker\"))\n\ndiabetes_data$Stroke &lt;- factor(diabetes_data$Stroke, levels = c(0, 1), labels = c(\"no_stroke\", \"stroke\"))\n\ndiabetes_data$HeartDiseaseorAttack &lt;- factor(diabetes_data$HeartDiseaseorAttack, levels = c(0, 1), labels = c(\"no_hd_or_attack\", \"hd_or_attack\"))\n\ndiabetes_data$PhysActivity &lt;- factor(diabetes_data$PhysActivity, levels = c(0, 1), labels = c(\"no_activity\", \"activity\"))\n\ndiabetes_data$Fruits &lt;- factor(diabetes_data$Fruits, levels = c(0, 1), labels = c(\"no_fruits\", \"fruits\"))\n\ndiabetes_data$Veggies &lt;- factor(diabetes_data$Veggies, levels = c(0, 1), labels = c(\"no_veggies\", \"veggies\"))\n\ndiabetes_data$HvyAlcoholConsump &lt;- factor(diabetes_data$HvyAlcoholConsump, levels = c(0, 1), labels = c(\"no_heavy_alc\", \"heavy_alc\"))\n\ndiabetes_data$AnyHealthcare &lt;- factor(diabetes_data$AnyHealthcare, levels = c(0, 1), labels = c(\"no_healthcare\", \"healthcare\"))\n\ndiabetes_data$NoDocbcCost &lt;- factor(diabetes_data$NoDocbcCost, levels = c(0, 1), labels = c(\"no_cost_issue\", \"cost_issue\"))\n\ndiabetes_data$GenHlth &lt;- factor(diabetes_data$GenHlth, levels = c(1, 2, 3, 4, 5), labels = c(\"excellent\", \"very_good\", \"good\", \"fair\", \"poor\"))\n\ndiabetes_data$DiffWalk &lt;- factor(diabetes_data$DiffWalk, levels = c(0, 1), labels = c(\"no_difficulty\", \"difficulty\"))\n\ndiabetes_data$Sex &lt;- factor(diabetes_data$Sex, levels = c(0, 1), labels = c(\"female\", \"male\"))\n\ndiabetes_data$Age &lt;- factor(diabetes_data$Age, levels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13), labels = c(\"18_24\", \"25_29\", \"30_34\", \"35_39\", \"40_44\", \"45_49\", \"50_54\", \"55_59\", \"60_64\", \"65_69\", \"70_74\", \"75_79\", \"80_or_more\"))\n\ndiabetes_data$Education &lt;- factor(diabetes_data$Education, levels = c(1, 2, 3, 4, 5, 6), labels = c(\"none\", \"elementary\", \"some_hs\", \"high_school\", \"some_college\", \"college_grad\"))\n\ndiabetes_data$Income &lt;- factor(diabetes_data$Income, levels = c(1, 2, 3, 4, 5, 6, 7, 8), labels = c(\"less_10k\", \"10k_15k\", \"15k_20k\", \"20k_25k\", \"25k_35k\", \"35k_50k\", \"50k_75k\", \"more_75k\"))\n\n#Check that columns have been converted correctly.\ndiabetes_data\n\n# A tibble: 253,680 × 22\n   Diabetes_binary HighBP HighChol     CholCheck       BMI Smoker     Stroke   \n   &lt;fct&gt;           &lt;fct&gt;  &lt;fct&gt;        &lt;fct&gt;         &lt;dbl&gt; &lt;fct&gt;      &lt;fct&gt;    \n 1 no_diabetes     hbp    high_chol    chol_check       40 smoker     no_stroke\n 2 no_diabetes     no_hbp no_high_chol no_chol_check    25 smoker     no_stroke\n 3 no_diabetes     hbp    high_chol    chol_check       28 non_smoker no_stroke\n 4 no_diabetes     hbp    no_high_chol chol_check       27 non_smoker no_stroke\n 5 no_diabetes     hbp    high_chol    chol_check       24 non_smoker no_stroke\n 6 no_diabetes     hbp    high_chol    chol_check       25 smoker     no_stroke\n 7 no_diabetes     hbp    no_high_chol chol_check       30 smoker     no_stroke\n 8 no_diabetes     hbp    high_chol    chol_check       25 smoker     no_stroke\n 9 diabetes        hbp    high_chol    chol_check       30 smoker     no_stroke\n10 no_diabetes     no_hbp no_high_chol chol_check       24 non_smoker no_stroke\n# ℹ 253,670 more rows\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;fct&gt;, PhysActivity &lt;fct&gt;,\n#   Fruits &lt;fct&gt;, Veggies &lt;fct&gt;, HvyAlcoholConsump &lt;fct&gt;, AnyHealthcare &lt;fct&gt;,\n#   NoDocbcCost &lt;fct&gt;, GenHlth &lt;fct&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;fct&gt;, Sex &lt;fct&gt;, Age &lt;fct&gt;, Education &lt;fct&gt;, Income &lt;fct&gt;\n\n#Missing Data - There are no missing values in this dataset.\nmissing_vals &lt;- colSums(is.na(diabetes_data))\nmissing_vals\n\n     Diabetes_binary               HighBP             HighChol \n                   0                    0                    0 \n           CholCheck                  BMI               Smoker \n                   0                    0                    0 \n              Stroke HeartDiseaseorAttack         PhysActivity \n                   0                    0                    0 \n              Fruits              Veggies    HvyAlcoholConsump \n                   0                    0                    0 \n       AnyHealthcare          NoDocbcCost              GenHlth \n                   0                    0                    0 \n            MentHlth             PhysHlth             DiffWalk \n                   0                    0                    0 \n                 Sex                  Age            Education \n                   0                    0                    0 \n              Income \n                   0 \n\n\n\n\nSummarizations\nHere I will create graphical and numerical summaries on the variables above. Based on the summaries that follow, I have determined the most important variables in their relationship with Diabetes are:\n\nHigh Blood Pressure Summary\nOf those without diabetes, 37.7% have high blood pressure. Of those with diabetes, 75.3% have high blood pressure. This does appear to be a significant predictor.\n\n#Bar plot of Diabetes with HighBP\nggplot(diabetes_data, aes(x = Diabetes_binary, fill = HighBP)) +\n  geom_bar()\n\n\n\n#Numeric summary of Diabetes with HBP.\nhbp_percent &lt;- diabetes_data |&gt;\n  group_by(Diabetes_binary) |&gt;\n  summarize(\n    hbp_count = sum(HighBP == \"hbp\"),\n    total_count = n(),\n    hbp_percent = (hbp_count / total_count) * 100\n  )\nhbp_percent\n\n# A tibble: 2 × 4\n  Diabetes_binary hbp_count total_count hbp_percent\n  &lt;fct&gt;               &lt;int&gt;       &lt;int&gt;       &lt;dbl&gt;\n1 no_diabetes         82225      218334        37.7\n2 diabetes            26604       35346        75.3\n\n\n\n\nHigh Cholesterol Summary\nOf those without diabetes, 38.4% have high blood pressure. Of those with diabetes, 67% have high cholesterol. This does appear to be a significant predictor.\n\n#Bar plot of Diabetes with HighChol\nggplot(diabetes_data, aes(x = Diabetes_binary, fill = HighChol)) +\n  geom_bar()\n\n\n\n#Numeric summary of Diabetes with high cholesterol.\nhigh_chol_percent &lt;- diabetes_data |&gt;\n  group_by(Diabetes_binary) |&gt;\n  summarize(\n    high_chol_count = sum(HighChol == \"high_chol\"),\n    total_count = n(),\n    high_chol_percent = (high_chol_count / total_count) * 100\n  )\nhigh_chol_percent\n\n# A tibble: 2 × 4\n  Diabetes_binary high_chol_count total_count high_chol_percent\n  &lt;fct&gt;                     &lt;int&gt;       &lt;int&gt;             &lt;dbl&gt;\n1 no_diabetes               83905      218334              38.4\n2 diabetes                  23686       35346              67.0\n\n\n\n\nCholesterol Check Summary\nOf those without diabetes, 95.8% have had a cholesterol check in the last five years. Of those with diabetes, 75.3% have had a cholesterol check. This does NOT appear to be a significant predictor.\n\n#Bar plot of Diabetes with Choleserol Check.\nggplot(diabetes_data, aes(x = Diabetes_binary, fill = CholCheck)) +\n  geom_bar()\n\n\n\n#Numeric summary of Diabetes with Cholesterol Check.\nchol_check_percent &lt;- diabetes_data |&gt;\n  group_by(Diabetes_binary) |&gt;\n  summarize(\n    chol_check_count = sum(CholCheck == \"chol_check\"),\n    total_count = n(),\n    chol_check_percent = (chol_check_count / total_count) * 100\n  )\nchol_check_percent\n\n# A tibble: 2 × 4\n  Diabetes_binary chol_check_count total_count chol_check_percent\n  &lt;fct&gt;                      &lt;int&gt;       &lt;int&gt;              &lt;dbl&gt;\n1 no_diabetes               209105      218334               95.8\n2 diabetes                   35105       35346               99.3\n\n\n\n\nBMI Summary\nOf those without diabetes, the mean BMI is 27.8 and standard deviation of 6.3 Of those with diabetes, the mean BMI is 31.9 with a standard deviation of 7.4 This does NOT appear to be a significant predictor.\n\n#BMI Graphical Display\nggplot(diabetes_data, aes(x = BMI, fill = Diabetes_binary)) +\n  geom_density(alpha = 0.5)\n\n\n\n#Numeric summary of Diabetes with BMI. \nbmi_numeric &lt;- diabetes_data |&gt;\n  group_by(Diabetes_binary) |&gt;\n  summarize(\n    mean_bmi = mean(BMI),\n    median_bmi = median(BMI)\n  )\nbmi_numeric\n\n# A tibble: 2 × 3\n  Diabetes_binary mean_bmi median_bmi\n  &lt;fct&gt;              &lt;dbl&gt;      &lt;dbl&gt;\n1 no_diabetes         27.8         27\n2 diabetes            31.9         31\n\n\n\n\nSmoker Summary\nOf those without diabetes, 43.1% smoke. Of those with diabetes, 51.8% smoke. This does NOT appear to be a significant predictor.\n\n#Bar plot of Diabetes with Smoker status\nggplot(diabetes_data, aes(x = Diabetes_binary, fill = Smoker)) +\n  geom_bar()\n\n\n\n#Numeric summary of Diabetes with Smoker status. \n\nsmoker_percent &lt;- diabetes_data |&gt;\n  group_by(Diabetes_binary) |&gt;\n  summarize(\n    smoker_count = sum(Smoker == \"smoker\"),\n    total_count = n(),\n    smoker_percent = (smoker_count / total_count) * 100\n  )\nsmoker_percent\n\n# A tibble: 2 × 4\n  Diabetes_binary smoker_count total_count smoker_percent\n  &lt;fct&gt;                  &lt;int&gt;       &lt;int&gt;          &lt;dbl&gt;\n1 no_diabetes            94106      218334           43.1\n2 diabetes               18317       35346           51.8\n\n\n\n\nStroke Summary\nOf those without diabetes, 3.22% have had a stroke. Of those with diabetes, 9.25% have had a stroke. This does NOT appear to be a significant predictor.\n\n#Bar plot of Diabetes with Incidence of Stroke\nggplot(diabetes_data, aes(x = Diabetes_binary, fill = Stroke)) +\n  geom_bar()\n\n\n\n#Numeric summary of Diabetes with incidence of stroke. \nstroke_percent &lt;- diabetes_data |&gt;\n  group_by(Diabetes_binary) |&gt;\n  summarize(\n    stroke_count = sum(Stroke == \"stroke\"),\n    total_count = n(),\n    stroke_percent = (stroke_count / total_count) * 100\n  )\nstroke_percent\n\n# A tibble: 2 × 4\n  Diabetes_binary stroke_count total_count stroke_percent\n  &lt;fct&gt;                  &lt;int&gt;       &lt;int&gt;          &lt;dbl&gt;\n1 no_diabetes             7024      218334           3.22\n2 diabetes                3268       35346           9.25\n\n\n\n\nHeart Disease or Attack Summary\nOf those without diabetes, 37.7% have high blood pressure. Of those with diabetes, 75.3% have high blook pressure. This does appear to be a significant predictor.\n\n#Bar plot of Diabetes with Heart Disease or Attack\nggplot(diabetes_data, aes(x = Diabetes_binary, fill = HeartDiseaseorAttack)) +\n  geom_bar()\n\n\n\n#Numeric summary of Diabetes with incidence of heart disease or attack. \nhd_or_attack_percent &lt;- diabetes_data |&gt;\n  group_by(Diabetes_binary) |&gt;\n  summarize(\n    hd_or_attack_count = sum(HeartDiseaseorAttack == \"hd_or_attack\"),\n    total_count = n(),\n    hd_or_attack_percent = (hd_or_attack_count / total_count) * 100\n  )\nhd_or_attack_percent\n\n# A tibble: 2 × 4\n  Diabetes_binary hd_or_attack_count total_count hd_or_attack_percent\n  &lt;fct&gt;                        &lt;int&gt;       &lt;int&gt;                &lt;dbl&gt;\n1 no_diabetes                  16015      218334                 7.34\n2 diabetes                      7878       35346                22.3 \n\n\n\n\nPhysical Activity Summary\nOf those without diabetes, 77.7% have exercised in the last 30 days outside of their job. Of those with diabetes, 63.1% have exercised in the last 30 days outside of their job. This does NOT appear to be a significant predictor.\n\n#Bar plot of Diabetes with Physical Activity\nggplot(diabetes_data, aes(x = Diabetes_binary, fill = PhysActivity)) +\n  geom_bar()\n\n\n\n#Numeric summary of diabetes with physical activity.\nactivity_percent &lt;- diabetes_data |&gt;\n  group_by(Diabetes_binary) |&gt;\n  summarize(\n    activity_count = sum(PhysActivity == \"activity\"),\n    total_count = n(),\n    activity_percent = (activity_count / total_count) * 100\n  )\nactivity_percent\n\n# A tibble: 2 × 4\n  Diabetes_binary activity_count total_count activity_percent\n  &lt;fct&gt;                    &lt;int&gt;       &lt;int&gt;            &lt;dbl&gt;\n1 no_diabetes             169633      218334             77.7\n2 diabetes                 22287       35346             63.1\n\n\n\n\nFruits Summary\nOf those without diabetes, 64.2% eat fruit at least once per day. Of those with diabetes, 58.5% eat fruit at least once per day. This does NOT appear to be a significant predictor.\n\n#Bar plot of Diabetes with Fruits\nggplot(diabetes_data, aes(x = Diabetes_binary, fill = Fruits)) +\n  geom_bar()\n\n\n\n#Numeric summary with fruits.\nfruit_percent &lt;- diabetes_data |&gt;\n  group_by(Diabetes_binary) |&gt;\n  summarize(\n    fruit_count = sum(Fruits == \"fruits\"),\n    total_count = n(),\n    fruit_percent = (fruit_count / total_count) * 100\n  )\nfruit_percent\n\n# A tibble: 2 × 4\n  Diabetes_binary fruit_count total_count fruit_percent\n  &lt;fct&gt;                 &lt;int&gt;       &lt;int&gt;         &lt;dbl&gt;\n1 no_diabetes          140205      218334          64.2\n2 diabetes              20693       35346          58.5\n\n\n\n\nVeggies Summary\nOf those without diabetes, 82% eat vegetables at least once per day. Of those with diabetes, 75.6% eat vegetables at least once per day. This does NOT appear to be a significant predictor.\n\n#Bar plot of Diabetes with Veggies\nggplot(diabetes_data, aes(x = Diabetes_binary, fill = Veggies)) +\n  geom_bar()\n\n\n\n#Numeric summary of diabetes with veggies.\nveggies_percent &lt;- diabetes_data |&gt;\n  group_by(Diabetes_binary) |&gt;\n  summarize(\n    veggies_count = sum(Veggies == \"veggies\"),\n    total_count = n(),\n    veggies_percent = (veggies_count / total_count) * 100\n  )\nveggies_percent\n\n# A tibble: 2 × 4\n  Diabetes_binary veggies_count total_count veggies_percent\n  &lt;fct&gt;                   &lt;int&gt;       &lt;int&gt;           &lt;dbl&gt;\n1 no_diabetes            179105      218334            82.0\n2 diabetes                26736       35346            75.6\n\n\n\n\nHeavy Alcohol Consumption Summary\nOf those without diabetes, 6.15% drink at least 14 drinks per week (male) or at least 7 drinks per week (female). Of those with diabetes, 2.35% drink at least 14 drinks per week (male) or at least 7 drinks per week (female). This does not appear to be a significant predictor.\n\n#Bar plot of Diabetes with Heavy Alcohol Consumption\nggplot(diabetes_data, aes(x = Diabetes_binary, fill = HvyAlcoholConsump)) +\n  geom_bar()\n\n\n\n#Numeric summary of diabetes with heavy alcohol consumers.\nalcohol_percent &lt;- diabetes_data |&gt;\n  group_by(Diabetes_binary) |&gt;\n  summarize(\n    alcohol_count = sum(HvyAlcoholConsump == \"heavy_alc\"),\n    total_count = n(),\n    alcohol_percent = (alcohol_count / total_count) * 100\n  )\n\n\n\nHealthcare Summary\nOf those without diabetes, 95% have health coverage. Of those with diabetes, 96% have health coverage. This does NOT appear to be a significant predictor.\n\n#Bar plot of Diabetes with Healthcare\nggplot(diabetes_data, aes(x = Diabetes_binary, fill = AnyHealthcare)) +\n  geom_bar()\n\n\n\n#Numeric summary of diabetes with healthcare coverage.\nhealthcare_percent &lt;- diabetes_data |&gt;\n  group_by(Diabetes_binary) |&gt;\n  summarize(\n    healthcare_count = sum(AnyHealthcare == \"healthcare\"),\n    total_count = n(),\n    healthcare_percent = (healthcare_count / total_count) * 100\n  )\nhealthcare_percent\n\n# A tibble: 2 × 4\n  Diabetes_binary healthcare_count total_count healthcare_percent\n  &lt;fct&gt;                      &lt;int&gt;       &lt;int&gt;              &lt;dbl&gt;\n1 no_diabetes               207339      218334               95.0\n2 diabetes                   33924       35346               96.0\n\n\n\n\nAvoiding Doctor due to Cost Summary\nOf those without diabetes, 8.07% have avoided the doctor because of cost. Of those with diabetes, 10.6% have avoided the doctor because of cost. This does not appear to be a significant predictor.\n\n#Bar plot of Diabetes with No Doctor because Cost\nggplot(diabetes_data, aes(x = Diabetes_binary, fill = NoDocbcCost)) +\n  geom_bar()\n\n\n\n#Numeric summary of Diabetes with No Doctor because cost.\ndoc_cost_percent &lt;- diabetes_data |&gt;\n  group_by(Diabetes_binary) |&gt;\n  summarize(\n    doc_cost_count = sum(NoDocbcCost == \"cost_issue\"),\n    total_count = n(),\n    doc_cost_percent = (doc_cost_count / total_count) * 100\n  )\ndoc_cost_percent\n\n# A tibble: 2 × 4\n  Diabetes_binary doc_cost_count total_count doc_cost_percent\n  &lt;fct&gt;                    &lt;int&gt;       &lt;int&gt;            &lt;dbl&gt;\n1 no_diabetes              17612      218334             8.07\n2 diabetes                  3742       35346            10.6 \n\n\n\n\nGeneral Health Rating Summary\n\n#Bar plot of Diabetes with No Doctor because Cost\nggplot(diabetes_data, aes(x = Diabetes_binary, fill = NoDocbcCost)) +\n  geom_bar()\n\n\n\ndoc_cost_percent &lt;- diabetes_data |&gt;\n  group_by(Diabetes_binary) |&gt;\n  summarize(\n    doc_cost_count = sum(NoDocbcCost == \"cost_issue\"),\n    total_count = n(),\n    doc_cost_percent = (doc_cost_count / total_count) * 100\n  )\ndoc_cost_percent\n\n# A tibble: 2 × 4\n  Diabetes_binary doc_cost_count total_count doc_cost_percent\n  &lt;fct&gt;                    &lt;int&gt;       &lt;int&gt;            &lt;dbl&gt;\n1 no_diabetes              17612      218334             8.07\n2 diabetes                  3742       35346            10.6 \n\n#Bar plot of Diabetes with General Health\nggplot(diabetes_data, aes(x = Diabetes_binary, fill = GenHlth)) +\n  geom_bar()\n\n\n\ngeneral_health_percent &lt;- diabetes_data |&gt;\n  group_by(Diabetes_binary) |&gt;\n  summarize(\n    total_count = n(),\n    excellent_count = sum(GenHlth == \"excellent\"),\n    excellent_percent = (excellent_count / total_count) * 100,\n    very_good_count = sum(GenHlth == \"very_good\"),\n    very_good_percent = (very_good_count / total_count) * 100,\n    good_count = sum(GenHlth == \"good\"),\n    good_percent = (good_count / total_count) * 100,\n    fair_count = sum(GenHlth == \"fair\"),\n    fair_percent = (fair_count / total_count) * 100,\n    poor_count = sum(GenHlth == \"poor\"),\n    poor_percent = (poor_count / total_count) * 100\n  )\ngeneral_health_percent\n\n# A tibble: 2 × 12\n  Diabetes_binary total_count excellent_count excellent_percent very_good_count\n  &lt;fct&gt;                 &lt;int&gt;           &lt;int&gt;             &lt;dbl&gt;           &lt;int&gt;\n1 no_diabetes          218334           44159             20.2            82703\n2 diabetes              35346            1140              3.23            6381\n# ℹ 7 more variables: very_good_percent &lt;dbl&gt;, good_count &lt;int&gt;,\n#   good_percent &lt;dbl&gt;, fair_count &lt;int&gt;, fair_percent &lt;dbl&gt;, poor_count &lt;int&gt;,\n#   poor_percent &lt;dbl&gt;\n\n#Mental Health Days\nggplot(diabetes_data, aes(x = MentHlth, fill = Diabetes_binary)) +\n  geom_boxplot()\n\n\n\nmental_health_num &lt;- diabetes_data |&gt;\n  group_by(Diabetes_binary) |&gt;\n  summarize(\n    mean_mental_hlth = mean(MentHlth),\n    median_mental_hlth = median(MentHlth)\n  )\nmental_health_num\n\n# A tibble: 2 × 3\n  Diabetes_binary mean_mental_hlth median_mental_hlth\n  &lt;fct&gt;                      &lt;dbl&gt;              &lt;dbl&gt;\n1 no_diabetes                 2.98                  0\n2 diabetes                    4.46                  0\n\n#Physical Illness or Injury in last 30 days\nggplot(diabetes_data, aes(x = PhysHlth, fill = Diabetes_binary)) +\n  geom_boxplot()\n\n\n\nphys_health_num &lt;- diabetes_data |&gt;\n  group_by(Diabetes_binary) |&gt;\n  summarize(\n    mean_mental_hlth = mean(PhysHlth),\n    median_mental_hlth = median(PhysHlth)\n  )\nphys_health_num\n\n# A tibble: 2 × 3\n  Diabetes_binary mean_mental_hlth median_mental_hlth\n  &lt;fct&gt;                      &lt;dbl&gt;              &lt;dbl&gt;\n1 no_diabetes                 3.64                  0\n2 diabetes                    7.95                  1\n\n#Bar plot of Diabetes with Difficulty Walking\nggplot(diabetes_data, aes(x = Diabetes_binary, fill = DiffWalk)) +\n  geom_bar()\n\n\n\nwalking_percent &lt;- diabetes_data |&gt;\n  group_by(Diabetes_binary) |&gt;\n  summarize(\n    walking_count = sum(DiffWalk == \"difficulty\"),\n    total_count = n(),\n    walking_percent = (walking_count / total_count) * 100\n  )\nwalking_percent\n\n# A tibble: 2 × 4\n  Diabetes_binary walking_count total_count walking_percent\n  &lt;fct&gt;                   &lt;int&gt;       &lt;int&gt;           &lt;dbl&gt;\n1 no_diabetes             29554      218334            13.5\n2 diabetes                13121       35346            37.1\n\n#Bar plot of Diabetes with Sex\nggplot(diabetes_data, aes(x = Diabetes_binary, fill = Sex)) +\n  geom_bar()\n\n\n\nsex_percent &lt;- diabetes_data |&gt;\n  group_by(Diabetes_binary) |&gt;\n  summarize(\n    sex_count = sum(Sex == \"female\"),\n    total_count = n(),\n    sex_percent = (sex_count / total_count) * 100\n  )\nsex_percent\n\n# A tibble: 2 × 4\n  Diabetes_binary sex_count total_count sex_percent\n  &lt;fct&gt;               &lt;int&gt;       &lt;int&gt;       &lt;dbl&gt;\n1 no_diabetes        123563      218334        56.6\n2 diabetes            18411       35346        52.1\n\n#Bar plot of Diabetes with Education\nggplot(diabetes_data, aes(x = Diabetes_binary, fill = Education)) +\n  geom_bar()\n\n\n\nedu_percent &lt;- diabetes_data |&gt;\n  group_by(Diabetes_binary) |&gt;\n  summarize(\n    total_count = n(),\n    none_count = sum(Education == \"none\"),\n    none_percent = (none_count / total_count) * 100,\n    elem_count = sum(Education == \"elementary\"),\n    elem_percent = (elem_count / total_count) * 100,\n    some_hs_count = sum(Education == \"some_hs\"),\n    some_hs_percent = (some_hs_count / total_count) * 100,\n    hs_count = sum(Education == \"high_school\"),\n    hs_percent = (hs_count / total_count) * 100,\n    some_college_count = sum(Education == \"some_college\"),\n    some_college_percent = (some_college_count / total_count) * 100,\n    college_grad_count = sum(Education == \"college_grad\"),\n    college_grad_percent = (college_grad_count / total_count) * 100\n  )\nedu_percent\n\n# A tibble: 2 × 14\n  Diabetes_binary total_count none_count none_percent elem_count elem_percent\n  &lt;fct&gt;                 &lt;int&gt;      &lt;int&gt;        &lt;dbl&gt;      &lt;int&gt;        &lt;dbl&gt;\n1 no_diabetes          218334        127       0.0582       2860         1.31\n2 diabetes              35346         47       0.133        1183         3.35\n# ℹ 8 more variables: some_hs_count &lt;int&gt;, some_hs_percent &lt;dbl&gt;,\n#   hs_count &lt;int&gt;, hs_percent &lt;dbl&gt;, some_college_count &lt;int&gt;,\n#   some_college_percent &lt;dbl&gt;, college_grad_count &lt;int&gt;,\n#   college_grad_percent &lt;dbl&gt;\n\n#Bar plot of Diabetes with Income\nggplot(diabetes_data, aes(x = Diabetes_binary, fill = Income)) +\n  geom_bar()\n\n\n\nincome_percent &lt;- diabetes_data |&gt;\n  group_by(Diabetes_binary) |&gt;\n  summarize(\n    total_count = n(),\n    less_10k_count = sum(Income == \"less_10k\"),\n    less_10k_percent = (less_10k_count / total_count) * 100,\n    ten_fifteen_count = sum(Income == \"10k_15k\"),\n    ten_fifteen_percent = (ten_fifteen_count / total_count) * 100,\n    fifteen_twenty_count = sum(Income == \"15k_20k\"),\n    fifteen_twenty_percent = (fifteen_twenty_count / total_count) * 100,\n    twenty_twentyfive_count = sum(Income == \"20k_25k\"),\n    twenty_twentyfive_percent = (twenty_twentyfive_count / total_count) * 100,\n    twentyfive_thirtyfive_count = sum(Income == \"25k_35k\"),\n    twentyfive_thirtyfive_percent = (twentyfive_thirtyfive_count / total_count) * 100,\n    thirtyfive_fifty_count = sum(Income == \"35k_50k\"),\n    thirtyfive_fifty_percent = (thirtyfive_fifty_count / total_count) * 100,\n    fifty_seventyfive_count = sum(Income == \"50k_75k\"),\n    fifty_seventyfive_percent = (fifty_seventyfive_count / total_count) * 100,\n    greater_seventyfive_count = sum(Income == \"more_75k\"),\n    greater_seventyfive_percent = (greater_seventyfive_count / total_count) * 100\n  )\nincome_percent\n\n# A tibble: 2 × 18\n  Diabetes_binary total_count less_10k_count less_10k_percent ten_fifteen_count\n  &lt;fct&gt;                 &lt;int&gt;          &lt;int&gt;            &lt;dbl&gt;             &lt;int&gt;\n1 no_diabetes          218334           7428             3.40              8697\n2 diabetes              35346           2383             6.74              3086\n# ℹ 13 more variables: ten_fifteen_percent &lt;dbl&gt;, fifteen_twenty_count &lt;int&gt;,\n#   fifteen_twenty_percent &lt;dbl&gt;, twenty_twentyfive_count &lt;int&gt;,\n#   twenty_twentyfive_percent &lt;dbl&gt;, twentyfive_thirtyfive_count &lt;int&gt;,\n#   twentyfive_thirtyfive_percent &lt;dbl&gt;, thirtyfive_fifty_count &lt;int&gt;,\n#   thirtyfive_fifty_percent &lt;dbl&gt;, fifty_seventyfive_count &lt;int&gt;,\n#   fifty_seventyfive_percent &lt;dbl&gt;, greater_seventyfive_count &lt;int&gt;,\n#   greater_seventyfive_percent &lt;dbl&gt;\n\n\nClick here for the Modeling Page"
  },
  {
    "objectID": "Modeling.html",
    "href": "Modeling.html",
    "title": "ST 558 Final Project EDA Document",
    "section": "",
    "text": "Introduction\n\n\nlogLoss\nlog loss is calculated using the following formula: -\\frac{1}{N} \\sum_{i=1}^{N} [y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i)]\n\n\nRead in data\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.3.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndiabetes_data &lt;- read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndiabetes_data$Diabetes_binary &lt;- factor(diabetes_data$Diabetes_binary, levels = c(0, 1), labels = c(\"no_diabetes\", \"diabetes\"))\n\ndiabetes_data$HighBP &lt;- factor(diabetes_data$HighBP, levels = c(0, 1), labels = c(\"no_hbp\", \"hbp\"))\n\ndiabetes_data$HighChol &lt;- factor(diabetes_data$HighChol, levels = c(0, 1), labels = c(\"no_high_chol\", \"high_chol\"))\n\ndiabetes_data$CholCheck &lt;- factor(diabetes_data$CholCheck, levels = c(0, 1), labels = c(\"no_chol_check\", \"chol_check\"))\n\ndiabetes_data$Smoker &lt;- factor(diabetes_data$Smoker, levels = c(0, 1), labels = c(\"non_smoker\", \"smoker\"))\n\ndiabetes_data$Stroke &lt;- factor(diabetes_data$Stroke, levels = c(0, 1), labels = c(\"no_stroke\", \"stroke\"))\n\ndiabetes_data$HeartDiseaseorAttack &lt;- factor(diabetes_data$HeartDiseaseorAttack, levels = c(0, 1), labels = c(\"no_hd_or_attack\", \"hd_or_attack\"))\n\ndiabetes_data$PhysActivity &lt;- factor(diabetes_data$PhysActivity, levels = c(0, 1), labels = c(\"no_activity\", \"activity\"))\n\ndiabetes_data$Fruits &lt;- factor(diabetes_data$Fruits, levels = c(0, 1), labels = c(\"no_fruits\", \"fruits\"))\n\ndiabetes_data$Veggies &lt;- factor(diabetes_data$Veggies, levels = c(0, 1), labels = c(\"no_veggies\", \"veggies\"))\n\ndiabetes_data$HvyAlcoholConsump &lt;- factor(diabetes_data$HvyAlcoholConsump, levels = c(0, 1), labels = c(\"no_heavy_alc\", \"heavy_alc\"))\n\ndiabetes_data$AnyHealthcare &lt;- factor(diabetes_data$AnyHealthcare, levels = c(0, 1), labels = c(\"no_healthcare\", \"healthcare\"))\n\ndiabetes_data$NoDocbcCost &lt;- factor(diabetes_data$NoDocbcCost, levels = c(0, 1), labels = c(\"no_cost_issue\", \"cost_issue\"))\n\ndiabetes_data$GenHlth &lt;- factor(diabetes_data$GenHlth, levels = c(1, 2, 3, 4, 5), labels = c(\"excellent\", \"very_good\", \"good\", \"fair\", \"poor\"))\n\ndiabetes_data$DiffWalk &lt;- factor(diabetes_data$DiffWalk, levels = c(0, 1), labels = c(\"no_difficulty\", \"difficulty\"))\n\ndiabetes_data$Sex &lt;- factor(diabetes_data$Sex, levels = c(0, 1), labels = c(\"female\", \"male\"))\n\ndiabetes_data$Age &lt;- factor(diabetes_data$Age, levels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13), labels = c(\"18_24\", \"25_29\", \"30_34\", \"35_39\", \"40_44\", \"45_49\", \"50_54\", \"55_59\", \"60_64\", \"65_69\", \"70_74\", \"75_79\", \"80_or_more\"))\n\ndiabetes_data$Education &lt;- factor(diabetes_data$Education, levels = c(1, 2, 3, 4, 5, 6), labels = c(\"none\", \"elementary\", \"some_hs\", \"high_school\", \"some_college\", \"college_grad\"))\n\ndiabetes_data$Income &lt;- factor(diabetes_data$Income, levels = c(1, 2, 3, 4, 5, 6, 7, 8), labels = c(\"less_10k\", \"10k_15k\", \"15k_20k\", \"20k_25k\", \"25k_35k\", \"35k_50k\", \"50k_75k\", \"more_75k\"))\n\n\n\nSplit the Data\nFirst we are going to split the data into a training and test set. We do this so that we can evaluate the model on data that wasn’t used to fit the model. This helps us not to overfit the model and make sure that the model can generalize to data it hasn’t yet seen.\n\nlibrary(caret)\n\nWarning: package 'caret' was built under R version 4.3.3\n\n\nLoading required package: lattice\n\n\n\nAttaching package: 'caret'\n\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\n#Set the seed at 100 for reproducibility.\nset.seed(100)\n\n#Use the createDataPartition from the caret package. Get 70% of the rows.\ntrainIndex &lt;- createDataPartition(diabetes_data$Diabetes_binary, p =0.7, list = FALSE)\n#Assign those 70% to the training dataset.\ndiabetes_train &lt;- diabetes_data[trainIndex, ]\ndiabetes_train\n\n# A tibble: 177,577 × 22\n   Diabetes_binary HighBP HighChol     CholCheck       BMI Smoker     Stroke   \n   &lt;fct&gt;           &lt;fct&gt;  &lt;fct&gt;        &lt;fct&gt;         &lt;dbl&gt; &lt;fct&gt;      &lt;fct&gt;    \n 1 no_diabetes     hbp    high_chol    chol_check       40 smoker     no_stroke\n 2 no_diabetes     no_hbp no_high_chol no_chol_check    25 smoker     no_stroke\n 3 no_diabetes     hbp    no_high_chol chol_check       27 non_smoker no_stroke\n 4 no_diabetes     hbp    high_chol    chol_check       24 non_smoker no_stroke\n 5 no_diabetes     hbp    high_chol    chol_check       25 smoker     no_stroke\n 6 no_diabetes     hbp    no_high_chol chol_check       30 smoker     no_stroke\n 7 no_diabetes     hbp    high_chol    chol_check       25 smoker     no_stroke\n 8 diabetes        hbp    high_chol    chol_check       30 smoker     no_stroke\n 9 diabetes        no_hbp no_high_chol chol_check       25 smoker     no_stroke\n10 no_diabetes     hbp    high_chol    chol_check       34 smoker     no_stroke\n# ℹ 177,567 more rows\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;fct&gt;, PhysActivity &lt;fct&gt;,\n#   Fruits &lt;fct&gt;, Veggies &lt;fct&gt;, HvyAlcoholConsump &lt;fct&gt;, AnyHealthcare &lt;fct&gt;,\n#   NoDocbcCost &lt;fct&gt;, GenHlth &lt;fct&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;fct&gt;, Sex &lt;fct&gt;, Age &lt;fct&gt;, Education &lt;fct&gt;, Income &lt;fct&gt;\n\n#Assign the rows not selected in the trainIndex (30% of data) to the test dataset.\ndiabetes_test &lt;- diabetes_data[-trainIndex, ]\n\n\n\nLogistic Regression Models\nA logistic regression model is a generalized linear model that has a response that is a success/failure. In this case, 0 represents “failure” which is no diabetes and 1 represents success which is prediabetes. A logistic model uses a logit link (or log(odds)) to connect the average response with a linear function in the parameters.\n\nLogistic Model #1\nUse all chosen predictors as main effect terms.\n\nset.seed(50)\ntrctrl &lt;- trainControl(method = \"cv\", \n                       number = 5, \n                       classProbs = TRUE, \n                       summaryFunction = mnLogLoss)\n\nlog_fit_1 &lt;- train(Diabetes_binary ~ HighBP + HighChol + HeartDiseaseorAttack + GenHlth + DiffWalk,\n                   data = diabetes_train,\n                   method = \"glm\",\n                   family = \"binomial\",\n                   metric = \"logLoss\",\n                   preProcess = c(\"center\", \"scale\"),\n                   trControl = trctrl)\nlog_fit_1\n\nGeneralized Linear Model \n\n177577 samples\n     5 predictor\n     2 classes: 'no_diabetes', 'diabetes' \n\nPre-processing: centered (8), scaled (8) \nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 142062, 142061, 142062, 142061, 142062 \nResampling results:\n\n  logLoss  \n  0.3336977\n\n\n\n\nLogistic Model #2\n\nset.seed(50)\ntrctrl &lt;- trainControl(method = \"cv\", \n                       number = 5, \n                       classProbs = TRUE, \n                       summaryFunction = mnLogLoss)\n\nlog_fit_2 &lt;- train(Diabetes_binary ~ HighBP*HighChol + HeartDiseaseorAttack + GenHlth + DiffWalk,\n                   data = diabetes_train,\n                   method = \"glm\",\n                   family = \"binomial\",\n                   metric = \"logLoss\",\n                   preProcess = c(\"center\", \"scale\"),\n                   trControl = trctrl)\nlog_fit_2\n\nGeneralized Linear Model \n\n177577 samples\n     5 predictor\n     2 classes: 'no_diabetes', 'diabetes' \n\nPre-processing: centered (9), scaled (9) \nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 142062, 142061, 142062, 142061, 142062 \nResampling results:\n\n  logLoss  \n  0.3336023\n\n\n\n\nLogistic Model #3\n\nset.seed(50)\ntrctrl &lt;- trainControl(method = \"cv\", \n                       number = 5, \n                       classProbs = TRUE, \n                       summaryFunction = mnLogLoss)\n\nlog_fit_3 &lt;- train(Diabetes_binary ~ HighBP + HighChol*HeartDiseaseorAttack + GenHlth*DiffWalk,\n                   data = diabetes_train,\n                   method = \"glm\",\n                   family = \"binomial\",\n                   metric = \"logLoss\",\n                   preProcess = c(\"center\", \"scale\"),\n                   trControl = trctrl)\nlog_fit_3\n\nGeneralized Linear Model \n\n177577 samples\n     5 predictor\n     2 classes: 'no_diabetes', 'diabetes' \n\nPre-processing: centered (13), scaled (13) \nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 142062, 142061, 142062, 142061, 142062 \nResampling results:\n\n  logLoss  \n  0.3327473\n\n\n\n\n\nClassification Tree\nA classification tree is the idea of splitting up the predictor space into regions and having different predictions for each region. For a classification tree specifically, the goal is to predict group membership - no diabetes, or prediabetes/diabetes in this case. We will use the most prevalent class to predict. This method is very easy to understand, we don’t need to include interaction terms, we don’t need to scale, and we don’t need to utilize statistical assumptions.\n\n#Set seed for reproducibility.\nset.seed(50)\ntrctrl &lt;- trainControl(method = \"cv\", \n                       number = 5, \n                       classProbs = TRUE, \n                       summaryFunction = mnLogLoss)\n\n#Create the tuneGrid by making a dataframe of the cp parameter that starts at 0, goes to 0.1 and counts by 0.001.\ntune_parameter &lt;- data.frame(cp = seq(0, 0.1, by = 0.001))\n\n\n#Create a classification tree using predictors of HighBP, HighChol, Heart Disease or Attack, General Health Rating, and Difficulty Walking to predict the presence of diabetes.\n#Use rpart for the method.\n#Use the train control defined above (5 fold cross validation) and the tuneGrid defined above.\n\ndiabetes_train\n\n# A tibble: 177,577 × 22\n   Diabetes_binary HighBP HighChol     CholCheck       BMI Smoker     Stroke   \n   &lt;fct&gt;           &lt;fct&gt;  &lt;fct&gt;        &lt;fct&gt;         &lt;dbl&gt; &lt;fct&gt;      &lt;fct&gt;    \n 1 no_diabetes     hbp    high_chol    chol_check       40 smoker     no_stroke\n 2 no_diabetes     no_hbp no_high_chol no_chol_check    25 smoker     no_stroke\n 3 no_diabetes     hbp    no_high_chol chol_check       27 non_smoker no_stroke\n 4 no_diabetes     hbp    high_chol    chol_check       24 non_smoker no_stroke\n 5 no_diabetes     hbp    high_chol    chol_check       25 smoker     no_stroke\n 6 no_diabetes     hbp    no_high_chol chol_check       30 smoker     no_stroke\n 7 no_diabetes     hbp    high_chol    chol_check       25 smoker     no_stroke\n 8 diabetes        hbp    high_chol    chol_check       30 smoker     no_stroke\n 9 diabetes        no_hbp no_high_chol chol_check       25 smoker     no_stroke\n10 no_diabetes     hbp    high_chol    chol_check       34 smoker     no_stroke\n# ℹ 177,567 more rows\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;fct&gt;, PhysActivity &lt;fct&gt;,\n#   Fruits &lt;fct&gt;, Veggies &lt;fct&gt;, HvyAlcoholConsump &lt;fct&gt;, AnyHealthcare &lt;fct&gt;,\n#   NoDocbcCost &lt;fct&gt;, GenHlth &lt;fct&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;fct&gt;, Sex &lt;fct&gt;, Age &lt;fct&gt;, Education &lt;fct&gt;, Income &lt;fct&gt;\n\nclass_tree_diabetes &lt;- train(Diabetes_binary ~ HighBP + HighChol + HeartDiseaseorAttack + GenHlth + DiffWalk,\n                    data = diabetes_train,\n                    method = \"rpart\",\n                    metric = \"logLoss\",\n                    trControl = trctrl,\n                    tuneGrid = tune_parameter)\nclass_tree_diabetes\n\nCART \n\n177577 samples\n     5 predictor\n     2 classes: 'no_diabetes', 'diabetes' \n\nNo pre-processing\nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 142062, 142061, 142062, 142061, 142062 \nResampling results across tuning parameters:\n\n  cp     logLoss  \n  0.000  0.3602483\n  0.001  0.3692773\n  0.002  0.4037576\n  0.003  0.4037576\n  0.004  0.4037576\n  0.005  0.4037576\n  0.006  0.4037576\n  0.007  0.4037576\n  0.008  0.4037576\n  0.009  0.4037576\n  0.010  0.4037576\n  0.011  0.4037576\n  0.012  0.4037576\n  0.013  0.4037576\n  0.014  0.4037576\n  0.015  0.4037576\n  0.016  0.4037576\n  0.017  0.4037576\n  0.018  0.4037576\n  0.019  0.4037576\n  0.020  0.4037576\n  0.021  0.4037576\n  0.022  0.4037576\n  0.023  0.4037576\n  0.024  0.4037576\n  0.025  0.4037576\n  0.026  0.4037576\n  0.027  0.4037576\n  0.028  0.4037576\n  0.029  0.4037576\n  0.030  0.4037576\n  0.031  0.4037576\n  0.032  0.4037576\n  0.033  0.4037576\n  0.034  0.4037576\n  0.035  0.4037576\n  0.036  0.4037576\n  0.037  0.4037576\n  0.038  0.4037576\n  0.039  0.4037576\n  0.040  0.4037576\n  0.041  0.4037576\n  0.042  0.4037576\n  0.043  0.4037576\n  0.044  0.4037576\n  0.045  0.4037576\n  0.046  0.4037576\n  0.047  0.4037576\n  0.048  0.4037576\n  0.049  0.4037576\n  0.050  0.4037576\n  0.051  0.4037576\n  0.052  0.4037576\n  0.053  0.4037576\n  0.054  0.4037576\n  0.055  0.4037576\n  0.056  0.4037576\n  0.057  0.4037576\n  0.058  0.4037576\n  0.059  0.4037576\n  0.060  0.4037576\n  0.061  0.4037576\n  0.062  0.4037576\n  0.063  0.4037576\n  0.064  0.4037576\n  0.065  0.4037576\n  0.066  0.4037576\n  0.067  0.4037576\n  0.068  0.4037576\n  0.069  0.4037576\n  0.070  0.4037576\n  0.071  0.4037576\n  0.072  0.4037576\n  0.073  0.4037576\n  0.074  0.4037576\n  0.075  0.4037576\n  0.076  0.4037576\n  0.077  0.4037576\n  0.078  0.4037576\n  0.079  0.4037576\n  0.080  0.4037576\n  0.081  0.4037576\n  0.082  0.4037576\n  0.083  0.4037576\n  0.084  0.4037576\n  0.085  0.4037576\n  0.086  0.4037576\n  0.087  0.4037576\n  0.088  0.4037576\n  0.089  0.4037576\n  0.090  0.4037576\n  0.091  0.4037576\n  0.092  0.4037576\n  0.093  0.4037576\n  0.094  0.4037576\n  0.095  0.4037576\n  0.096  0.4037576\n  0.097  0.4037576\n  0.098  0.4037576\n  0.099  0.4037576\n  0.100  0.4037576\n\nlogLoss was used to select the optimal model using the smallest value.\nThe final value used for the model was cp = 0.\n\n\n\n\nRandom Forest\nA random forest extends the idea of bootstrap aggregation, but uses a random subset of predictors rather than all predictors. It can reduce the variance in comparison to a basic classification tree because you are averaging across trees.\n\n#Use rf for the method.\n#Use the train control defined above (repeated 10 fold cross validation) and the tuneGrid is from 1 to 5 because I have chosen five predictors.\n#Set seed for reproducibility and do 3 repeats of 10 fold cross validation.\nset.seed(50)\ntrctrl &lt;- trainControl(method = \"cv\", \n                       number = 5, \n                       classProbs = TRUE, \n                       summaryFunction = mnLogLoss)\n\n\nrf_model_diabetes &lt;- train(Diabetes_binary ~ HighBP + HighChol + HeartDiseaseorAttack + GenHlth + DiffWalk,\n                    data = diabetes_train,\n                    method = \"rf\",\n                    metric = \"logLoss\",\n                    trControl = trctrl,\n                    tuneGrid = data.frame(mtry = 1:5))\n\nrf_model_diabetes\n\nRandom Forest \n\n177577 samples\n     5 predictor\n     2 classes: 'no_diabetes', 'diabetes' \n\nNo pre-processing\nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 142062, 142061, 142062, 142061, 142062 \nResampling results across tuning parameters:\n\n  mtry  logLoss \n  1     4.159909\n  2     4.093489\n  3     4.101530\n  4     4.133644\n  5     4.149419\n\nlogLoss was used to select the optimal model using the smallest value.\nThe final value used for the model was mtry = 2.\n\n\n\n\nFinal Model Selection"
  }
]